{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "import collections\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import NearMiss\n",
    "# from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\".\\data\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for any null values\n",
    "data.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes are heavily skewed we need to solve this issue later.\n",
    "print('No Frauds', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset = ',data['Class'].value_counts()[0],'records')\n",
    "print('Frauds', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset = ',data['Class'].value_counts()[1],'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot('Class', data=data, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "\n",
    "bins = 50\n",
    "\n",
    "ax1.hist(df.Time[df.Class == 1], bins = bins)\n",
    "ax1.set_title('Fraud')\n",
    "\n",
    "ax2.hist(df.Time[df.Class == 0], bins = bins)\n",
    "ax2.set_title('Normal')\n",
    "\n",
    "plt.xlabel('Time (in Seconds)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seconds_in_day = 24*60*60\n",
    "\n",
    "df['sin_time'] = np.sin(2*np.pi*df.Time/seconds_in_day)\n",
    "df['cos_time'] = np.cos(2*np.pi*df.Time/seconds_in_day)\n",
    "\n",
    "df.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the features of this dataset, except for time and amount, have already undergone PCA transformation which mean that \n",
    "#they have already been scaled. In this step we will scale the 'Amount' feature.\n",
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, normalize, MinMaxScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# rob_scaler = RobustScaler()\n",
    "# # norm = normalize()\n",
    "mm_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "df['scaled_amount'] = mm_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df.drop('Amount', axis=1, inplace=True)\n",
    "# #df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "# # df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "# Lets shuffle the data before creating the subsamples\n",
    "X_orig = df.drop('Class', axis=1)\n",
    "y_orig = df['Class']\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "df.head()\n",
    "\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans RI score : 0.003082901128496951\n",
      "f1 score : 0.006294806784402868\n",
      "precision : 0.0034436579299789555\n",
      "recall : 0.036585365853658534\n",
      "Average Precision-Recall Score : 0.0017902724220599945\n",
      "Accuracy : 0.9800461365064763\n"
     ]
    }
   ],
   "source": [
    "# Modeling the data as is using kmeans clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_orig)\n",
    "labels = kmeans.predict(X_orig)\n",
    "\n",
    "kmeans_RI = adjusted_rand_score(y_orig, labels)#calculate_rand_index(y, labels)#rand_index_score(y, labels)\n",
    "print(\"KMeans RI score :\",kmeans_RI)\n",
    "f1 = f1_score(y_orig, labels)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_orig, labels)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_orig, labels)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_orig, labels)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_orig, labels)\n",
    "print(\"Accuracy :\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans RI score : 0.0001413498983376267\n",
      "f1 score : 0.6584531143052703\n",
      "precision : 0.49638802889576883\n",
      "recall : 0.9776422764227642\n",
      "Average Precision-Recall Score : 0.4964687843472862\n",
      "Accuracy : 0.4928861788617886\n"
     ]
    }
   ],
   "source": [
    "# # Modeling the data as is using AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, linkage=\"complete\").fit_predict(X)\n",
    "\n",
    "kmeans_RI = adjusted_rand_score(y, clustering)#calculate_rand_index(y, labels)#rand_index_score(y, labels)\n",
    "print(\"KMeans RI score :\",kmeans_RI)\n",
    "f1 = f1_score(y, clustering)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y, clustering)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y, clustering)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y, clustering)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y, clustering)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try these same clustering algorithms with over sampling the under represented(fraud) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# # Separate input features and target\n",
    "# y = df.Class\n",
    "# X = df.drop('Class', axis=1)\n",
    "\n",
    "X_new = df.copy()\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud = X_new[X_new.Class==0]\n",
    "fraud = X_new[X_new.Class==1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "upsampled.Class.value_counts()\n",
    "\n",
    "y_upsampled = upsampled.Class\n",
    "X_upsampled = upsampled.drop('Class', axis=1)\n",
    "\n",
    "#### For AGNEST\n",
    "upsampled = upsampled.sample(frac=1, random_state=42)\n",
    "\n",
    "fraud_df = upsampled.loc[upsampled['Class'] == 1][:900]\n",
    "non_fraud_df = upsampled.loc[upsampled['Class'] == 0][:900]\n",
    "\n",
    "new_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = new_df.sample(frac=1, random_state=42)\n",
    "\n",
    "X_agnest = new_df.drop('Class', axis=1)\n",
    "y_agnest = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.12803959475254872\n",
      "precision : 0.6775770242027911\n",
      "recall : 0.07069975203559432\n",
      "Average Precision-Recall Score : 0.5125546515783561\n",
      "Accuracy : 0.5185287445263176\n"
     ]
    }
   ],
   "source": [
    "# Modeling the upsampled data as is using kmeans clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_upsampled)\n",
    "labels = kmeans.predict(X_upsampled)\n",
    "\n",
    "f1 = f1_score(y_upsampled, labels)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_upsampled, labels)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_upsampled, labels)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_upsampled, labels)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_upsampled, labels)\n",
    "print(\"Accuracy :\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans RI score : -9.78610199803425e-06\n",
      "f1 score : 0.015350877192982457\n",
      "precision : 0.5833333333333334\n",
      "recall : 0.0077777777777777776\n",
      "Average Precision-Recall Score : 0.5006481481481482\n",
      "Accuracy : 0.5011111111111111\n"
     ]
    }
   ],
   "source": [
    "# Modeling the upsampled data as is using AgglomerativeClustering\n",
    "# amount of fraud classes 492 rows.\n",
    "\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, linkage=\"complete\").fit_predict(X_agnest)\n",
    "\n",
    "kmeans_RI = adjusted_rand_score(y_agnest, clustering)#calculate_rand_index(y, labels)#rand_index_score(y, labels)\n",
    "print(\"KMeans RI score :\",kmeans_RI)\n",
    "f1 = f1_score(y_agnest, clustering)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_agnest, clustering)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_agnest, clustering)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_agnest, clustering)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_agnest, clustering)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try under sampling the over-represented negative(non-fraud) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Class.value_counts()\n",
    "\n",
    "y_undersampled = downsampled.Class\n",
    "X_undersampled = downsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.1347905282331512\n",
      "precision : 0.6491228070175439\n",
      "recall : 0.07520325203252033\n",
      "Average Precision-Recall Score : 0.5112145200399373\n",
      "Accuracy : 0.5172764227642277\n"
     ]
    }
   ],
   "source": [
    "# Modeling the undersampled data as is using kmeans clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_undersampled)\n",
    "labels = kmeans.predict(X_undersampled)\n",
    "\n",
    "f1 = f1_score(y_undersampled, labels)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_undersampled, labels)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_undersampled, labels)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_undersampled, labels)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_undersampled, labels)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.6602608098833219\n",
      "precision : 0.49844559585492226\n",
      "recall : 0.9776422764227642\n",
      "Average Precision-Recall Score : 0.4984803487931252\n",
      "Accuracy : 0.4969512195121951\n"
     ]
    }
   ],
   "source": [
    "# Modeling the undersampled data as is using AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, linkage=\"complete\").fit_predict(X_undersampled)\n",
    "\n",
    "f1 = f1_score(y_undersampled, clustering)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_undersampled, clustering)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_undersampled, clustering)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_undersampled, clustering)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_undersampled, clustering)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try over-sampling the under-represented class using SMOTE(Synthetic Minority Over-sampling Technique) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "sm = SMOTE(random_state=27)#, ratio=1.0)\n",
    "X_smote, y_smote = sm.fit_sample(X, y)\n",
    "\n",
    "X_agnest = X_smote[:500]\n",
    "y_agnest = y_smote[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.13228178458490494\n",
      "precision : 0.6796959117752618\n",
      "recall : 0.0732708439582857\n",
      "Average Precision-Recall Score : 0.513166471111627\n",
      "Accuracy : 0.5193711200604962\n"
     ]
    }
   ],
   "source": [
    "# Modeling the undersampled data using SMOTE and kmeans clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_smote)\n",
    "labels = kmeans.predict(X_smote)\n",
    "\n",
    "f1 = f1_score(y_smote, labels)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_smote, labels)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_smote, labels)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_smote, labels)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_smote, labels)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.004065040650406504\n",
      "precision : 0.002036659877800407\n",
      "recall : 1.0\n",
      "Average Precision-Recall Score : 0.002036659877800407\n",
      "Accuracy : 0.02\n"
     ]
    }
   ],
   "source": [
    "# Modeling the undersampled data using SMOTE and AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2, linkage=\"complete\").fit_predict(X_agnest)\n",
    "\n",
    "f1 = f1_score(y_agnest, clustering)\n",
    "print(\"f1 score :\", f1)\n",
    "precision = precision_score(y_agnest, clustering)\n",
    "print(\"precision :\",precision)\n",
    "recall = recall_score(y_agnest, clustering)\n",
    "print(\"recall :\",recall)\n",
    "average_precision = average_precision_score(y_agnest, clustering)\n",
    "print(\"Average Precision-Recall Score :\",average_precision)\n",
    "accuracy = accuracy_score(y_agnest, clustering)\n",
    "print(\"Accuracy :\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
